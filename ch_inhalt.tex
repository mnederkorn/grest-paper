\section{Introduction}
\section{Definitions}
Foundational to our task are the different kinds of \textit{Infinite Games} and how to determine the outcome of each such game. To do so, we also want a notion of \textit{strategies} on such Infinite Games. To later reduce the games to one another, we furthermore want a definition of a \textit{Reduction} in the computational complexity sense.
\subsection{Directed Graphs}
Let $V$ be a finite set of Vertices, let $E\subseteq V \times V$ be a set of Edges, then $G = (V,E)$ is a \textit{Directed Graph}.
We also define $src\colon E\rightarrow V$ as $src((u,v))=u$ and
$tgt\colon E\rightarrow V$ as $src((u,v))=v$.
\subsection{Arenas}
An arena is an extension of Directed Graphs, where the set of Vertices, $V$, is partitioned into two disjunct subsets $V_0$ and $V_1$, respectively denoting the regions where player 0 and player 1 are to play. We also require that the out-degree of every vertex is at least one, so that any play on the Arena can always be prolonged.\newline
Formally, let $(V,E)$ be a non-trivial Directed Graph, $V_0\cup V_1 = V,~V_0\cap V_1 = \emptyset$ be a partition of V and $\forall v\in V\colon \exists e \in E\colon src(e)=v$,
then $A=(V,(V_0,V_1),E)$ is an Arena.
\subsection{Positions, Moves}
A \textit{position}, $\pi_i=(v_0, v_1, ..., v_i)$, in a Game describes a finite path on the underlying graph, i.e. a position is an element of $V^+$.\newline
A \textit{move} is an extension of a position by one more step in the graph. E.g. $\pi_i\mapsto \pi_{i+1}$ for $(v_i, v_{i+1})\in E$. Player P as in $v_i\in V_P\in (V_0,V_1)$ chooses the move.
\subsection{Strategies}
A \textit{strategy}, $V^*\times V_P\rightarrow V$, is a function by which player $P$ choses the next move for any given position.\newline
We call a strategy \textit{memoryless} if for any given position the next move only depends on the last vertex of the position, i.e. $V_P\rightarrow V$.
We will refer to memoryless strategies of player 0 as $\sigma$ and of player 1 as $\tau$.
\subsection{Plays}
A \textit{play} describes the path of arbitrary length $\langle v_0, v_1, ...\rangle$ the player go trough in the process of playing the game.
We refer to the play generated by applying strategies $\sigma, \tau$ to game $G$ starting at $v_0 \in V$ as $\pi_{\sigma, \tau}(G, v_0)=\langle v_0, v_1, ...\rangle$
\subsection{Infinite Games}
Infinite Games are a category of games played by two players on a finite, directed graph. They are infinite in the sense that we require the out-degree of every vertex to be at least one. As such, regardless of the strategies chosen by the players, they never terminate.
\subsubsection{Parity Games}
Parity Games are played by two players, \textit{Even} or player 0, also represented by $\Square$ and \textit{Odd} or player 1, also represented by $\Circle$.\newline
A Parity Game, $PG =(A,p)$, is played on an Arena $A$ with a priority function $p\colon V\rightarrow\{0, 1, ..., \left|V\right|\}$.\newline
Let $\pi_{\sigma, \tau}(PG, v_0)=\langle v_0, v_1, ...\rangle$ be the \textit{play} resulting from applying the strategies $\sigma$ and $\tau$ to Parity Game $PG$.\newline
Let $\#_\infty(\pi_{\sigma, \tau}(PG, v_0))=\{i\in \langle p(v_0), p(v_1), ...\rangle\mid\forall j \in \mathbb{N}\colon j<\left| \langle v\in \langle v_0, v_1, ...\rangle\mid p(v)=i\rangle\right|\}$ be the set of priorities that appear arbitrarily often in the play. If $max(\#_\infty(\pi_{\sigma, \tau}(PG, v_0)))$ is Even, then \textit{Even} wins and vice versa.
\subsubsection{Mean Payoff Games}
Mean Payoff Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Mean Payoff Game, $MPG = (A,\nu,d,w)$, is played on an Arena $A$, with threshold $\nu \in \mathbb{Z}$ and an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$.\newline
\textit{Max} wins play $\pi_{\sigma, \tau}(MPG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	\liminf\limits_{n\rightarrow \infty} \left(\dfrac{1}{n}\sum_{i=0}^{n-1}w((v_i,v_{i+1}))\right)\geq\nu.
\end{align*}
\subsubsection{Energy Games}
Energy Games are played by two players, \textit{Charging} or player 0 ($\Square$) and \textit{Depleting} or player 1 ($\Circle$).\newline
An Energy Game, $EG = (A,c,d,w)$, is played on an Arena $A$, with credit $c\in\mathbb{N}_0$ and an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$.\newline
\textit{Charging} wins play $\pi_{\sigma, \tau}(EG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	\forall k\in\mathbb{N}_0\colon\left(\sum_{i=0}^{k}w((v_i,v_{i+1}))\right)+c\geq0.
\end{align*}
For any given position $\langle v_0, v_1, ..., v_k\rangle$ in a play we call $\left(\sum_{i=0}^{k-1}w((v_i,v_{i+1}))\right) + c$ the \textit{energy level} at that position. Keep in mind that \textit{Charging} doesn't necessarily aim to maximise their energy level at \textit{any} specific position but rather to maintain a non-negative energy level at \textit{every} position. In a sense, they aim to minimise the $c$ necessary to maintain the winning condition for any given position of a play.
\subsubsection{Discounted Payoff Games}
Discounted Payoff Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Discounted Payoff Game, $DPG = (A,\nu,d,w,\lambda)$, is played on an Arena $A$, with threshold $\nu \in \mathbb{Z}$, an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$ and a discount factor $0<\lambda<1$.\newline
\textit{Max} wins play $\pi_{\sigma, \tau}(DPG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	(1-\lambda)\left(\sum_{i=0}^{\infty}\lambda^i\cdot w((v_i,v_{i+1}))\right)\geq\nu.
\end{align*}
\subsection{Simple Stochastic Games}
Simple Stochastic Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Simple Stochastic Game, $SSG = (G, (V_{0}, V_{1}, V_{2}), V_-, V_+, p)$, is played on a Directed Graph G, with a partition $(V_{0}, V_{1}, V_{2})$, two sink vertices $V_-, V_+$ and a probability function $p\colon E\ni (V_{2}\times V)\rightarrow (0,1]$. We require that the probabilites of all outgoing edges of each $V_2$ vertex sum to 1:
\begin{align*}
	\forall v\in V_2\colon\left(\sum_{e\in E\colon src(e)=v}p(e)\right)=1
\end{align*}
We also require that the out-degree of every vertex is at least one, with the exception of $V_0, V_1$, for which it is zero.
We say that a SSG is \textit{stopping} if for every possible position in a play there is a path to one of the sink vertices.\newline
\textit{Max} wins if the $V_+$ sink is reached, \textit{Min} wins if the $V_-$ sink is reached or the game doesn't terminate.
Since the result of a play $\pi_{\sigma, \tau}(SSG, v_0)$ can be probablistic, it is assigned a probabilty to reach the $V_+$ sink rather than a fixed value.
Since SSGs can terminate, they are not Infinite Games. For simplicity, we henceforth still colloquially include SSG under the label \textit{Infinite Games}. Note that plays of non-stopping SSGs may still be arbitrarily long.
\subsection{Reductions}
\section{Reductions and Solutions in Theory}
\subsection{Reductions in Theory}
\subsubsection{PGs to MPGs}
\subsubsection{MPGs to DPGs}
\subsubsection{MPGs to EGs}
\subsubsection{DPGs to SSGs}
\subsection{Solutions in Theory}
\subsubsection{Value Iteration}
\subsubsection{Strategy Iteration}
\subsubsection{PGs}
\subsubsection{MPGs}
\subsubsection{DPGs}
\subsubsection{EGs}
\subsubsection{SSGs}
\section{Reductions and Solutions in Practise}
\subsection{Reductions in Practise}
\subsection{Solutions in Practise}
\section{Implementation}
\section{Evaluation}
\section{Conclusion and further approaches}
