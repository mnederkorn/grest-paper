\section{Introduction}
\section{Definitions}
Foundational to our task are the different kinds of \textit{Infinite Games} and how to determine the outcome of each such game. To do so, we also want a notion of \textit{strategies} on such Infinite Games. To later reduce the games to one another, we furthermore want a definition of a \textit{Reduction} in the computational complexity sense.
\subsection{Directed Graphs}
Let $V$ be a finite set of Vertices, let $E\subseteq V \times V$ be a set of Edges, then $G = (V,E)$ is a \textit{Directed Graph}.
We also define $src\colon E\rightarrow V$ as $src((u,v))=u$ and
$tgt\colon E\rightarrow V$ as $tgt((u,v))=v$.
\subsection{Arenas}
An arena is an extension of Directed Graphs, where the set of Vertices, $V$, is partitioned into two disjunct subsets $V_0$ and $V_1$, respectively denoting the regions where player 0, also represented by $\Square$, and player 1, also represented by $\Circle$, are to play. We also require that the out-degree of every vertex is at least one, so that any play on the Arena can always be prolonged.\newline
Formally, let $(V,E)$ be a non-trivial Directed Graph, $V_0\cup V_1 = V,~V_0\cap V_1 = \emptyset$ be a partition of V and $\forall v\in V\colon \exists e \in E\colon src(e)=v$,
then $A=(V,(V_0,V_1),E)$ is an Arena.

\begin{wrapfigure}[9]{l}{4.5cm}
	\begin{tikzpicture}
		\node[style={regular polygon,regular polygon sides=4}, draw=black] (A) at (0,0) {$v_0$};
		\node[style={regular polygon,regular polygon sides=4}, draw=black] (B) at (1.75,0) {$v_1$};
		\node[shape=circle, draw=black] (C) at (3.5,0) {$v_2$};
		\node[shape=circle, draw=black] (D) at (0,-1.75) {$v_3$};
		\node[shape=circle, draw=black] (E) at (3.5,-1.75) {$v_4$};
		\path [->] (A) edge (B);
		\path [->] (B) edge[out=15, in=165] (C);
		\path [->] (C) edge[out=195, in=345] (B);
		\path [->] (C) edge (E);
		\path [->] (E) edge[out=285, in=255,looseness=8] (E);
		\path [->] (A) edge (D);
		\path [->] (B) edge (D);
		\path [->] (D) edge[out=285, in=255,looseness=8] (D);
	\end{tikzpicture}
\caption{test}
\end{wrapfigure}

\textbf{Example 1:}\\
In Fig. 1: An Arena $A=((v_0,v_1,v_2,v_3,v_4),((v_0,v_1),(v_2,v_3,v_4)),$\\
$((v_0,v_1),(v_0,v_3),(v_1,v_2),(v_2,v_1),$\\
$(v_2,v_4),(v_4,v_4),(v_1,v_3),(v_3,v_3)))$
\subsection{Positions, Moves}
A \textit{position}, $\pi_i=(v_0, v_1, ..., v_i)$, in a Game describes a finite path on the underlying graph, i.e. a position is an element of $V^+$. E.g. in Fig. 1 starting at $v_0$, $(v_0,v_1,v_2,v_4)$ could be a play.\\
A \textit{move} is an extension of a position by one more step in the graph. E.g. in Fig. 1 $(v_0,v_1,v_2)\mapsto (v_0,v_1,v_2,v_4)$ could be move. Player P as in $v_i\in V_P\in (V_0,V_1)$ chooses the move.
\subsection{Strategies}
A \textit{strategy}, $V^*\times V_P\rightarrow V$, is a function by which player $P$ choses the next move for any given position.\newline
We call a strategy \textit{memoryless} if for any given position the next move only depends on the last vertex of the position, i.e. $V_P\rightarrow V$.
We will refer to memoryless strategies of player 0 as $\sigma$ and of player 1 as $\tau$.
\subsection{Plays}
A \textit{play} describes the path of arbitrary length $\langle v_0, v_1, ...\rangle$ the player go trough in the process of playing the game.
We refer to the play generated by applying strategies $\sigma, \tau$ to game $G$ starting at $v_0 \in V$ as $\pi_{\sigma, \tau}(G, v_0)=\langle v_0, v_1, ...\rangle$
\subsection{Infinite Games}
Infinite Games are a category of games played by two players on a finite, directed graph. They are infinite in the sense that we require the out-degree of every vertex to be at least one. As such, regardless of the strategies chosen by the players, they never terminate.
\subsubsection{Parity Games}
Parity Games are played by two players, \textit{Even} or player 0 ($\Square$) and \textit{Odd} or player 1 ($\Circle$).\newline
A Parity Game, $PG =(A,p)$, is played on an Arena $A$ with a priority function $p\colon V\rightarrow\{0, 1, ..., \left|V\right|\}$.\newline
Let $\pi_{\sigma, \tau}(PG, v_0)=\langle v_0, v_1, ...\rangle$ be the \textit{play} resulting from applying the strategies $\sigma$ and $\tau$ to Parity Game $PG$.\newline
Let $\#_\infty(\pi_{\sigma, \tau}(PG, v_0))=\{i\in \langle p(v_0), p(v_1), ...\rangle\mid\forall j \in \mathbb{N}\colon j<\left| \langle v\in \langle v_0, v_1, ...\rangle\mid p(v)=i\rangle\right|\}$ be the set of priorities that appear arbitrarily often in the play. If $max(\#_\infty(\pi_{\sigma, \tau}(PG, v_0)))$ is Even, then \textit{Even} wins and vice versa.
\subsubsection{Mean Payoff Games}
Mean Payoff Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Mean Payoff Game, $MPG = (A,\nu,d,w)$, is played on an Arena $A$, with threshold $\nu \in \mathbb{Z}$ and an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$.\newline
\textit{Max} wins play $\pi_{\sigma, \tau}(MPG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	\liminf\limits_{n\rightarrow \infty} \left(\dfrac{1}{n}\sum_{i=0}^{n-1}w((v_i,v_{i+1}))\right)\geq\nu.
\end{align*}
\subsubsection{Energy Games}
Energy Games are played by two players, \textit{Charging} or player 0 ($\Square$) and \textit{Depleting} or player 1 ($\Circle$).\newline
An Energy Game, $EG = (A,c,d,w)$, is played on an Arena $A$, with credit $c\in\mathbb{N}_0$ and an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$.\newline
\textit{Charging} wins play $\pi_{\sigma, \tau}(EG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	\forall k\in\mathbb{N}_0\colon\left(\sum_{i=0}^{k}w((v_i,v_{i+1}))\right)+c\geq0.
\end{align*}
For any given position $\langle v_0, v_1, ..., v_k\rangle$ in a play we call $\left(\sum_{i=0}^{k-1}w((v_i,v_{i+1}))\right) + c$ the \textit{energy level} at that position. Keep in mind that \textit{Charging} doesn't necessarily aim to maximise their energy level at \textit{any} specific position but rather to maintain a non-negative energy level at \textit{every} position. In a sense, they aim to minimise the $c$ necessary to maintain the winning condition for any given position of a play.
\subsubsection{Discounted Payoff Games}
Discounted Payoff Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Discounted Payoff Game, $DPG = (A,\nu,d,w,\lambda)$, is played on an Arena $A$, with threshold $\nu \in \mathbb{Z}$, an edge-weight function $w\colon E\rightarrow\{-d, ..., -1, 0, 1, ..., d\}$, $d\in \mathbb{N}_0$ and a discount factor $0<\lambda<1$.\newline
\textit{Max} wins play $\pi_{\sigma, \tau}(DPG, v_0)=\langle v_0, v_1, ...\rangle$ if
\begin{align*}
	(1-\lambda)\left(\sum_{i=0}^{\infty}\lambda^i\cdot w((v_i,v_{i+1}))\right)\geq\nu.
\end{align*}
\subsection{Simple Stochastic Games}
Simple Stochastic Games are played by two players, \textit{Max} or player 0 ($\Square$) and \textit{Min} or player 1 ($\Circle$).\newline
A Simple Stochastic Game, $SSG = (G, (V_{0}, V_{1}, V_{2}), V_-, V_+, p)$, is played on a Directed Graph G, with a partition $(V_{0}, V_{1}, V_{2})$, two sink vertices $V_-, V_+$ and a probability function $p\colon E\ni (V_{2}\times V)\rightarrow (0,1]$. We require that the probabilites of all outgoing edges of each $V_2$ vertex sum to 1:
\begin{align*}
	\forall v\in V_2\colon\left(\sum_{e\in E\colon src(e)=v}p(e)\right)=1
\end{align*}
We also require that the out-degree of every vertex is at least one, with the exception of $V_0, V_1$, for which it is zero.
We say that a SSG is \textit{stopping} if for every possible position in a play there is a path to one of the sink vertices.\newline
\textit{Max} wins if the $V_+$ sink is reached, \textit{Min} wins if the $V_-$ sink is reached or the game doesn't terminate.
Since the result of a play $\pi_{\sigma, \tau}(SSG, v_0)$ can be probablistic, it is assigned a probabilty to reach the $V_+$ sink rather than a fixed value.
Since SSGs can terminate, they are not Infinite Games. For simplicity, we henceforth still colloquially include SSG under the label \textit{Infinite Games}. Note that plays of non-stopping SSGs may still be arbitrarily long.
\subsection{Reductions}
A \textit{reduction} describes an algorithm with which we can transform (reduce) one class of problems to another. For our purposes, we choose target problem classes that are already solved. Aside from reducing to an already solved problem class and therefore, per definition, also solving the originial problem class, reducing and subsequent solving of instances of the original problem may be faster than any attempt to directly solve the original problem without an intermediary reduction.\newline
Formally, we express our problem classes as formal languages $A$ and $B$ over the alphabets $\Sigma^*$ and $\Gamma^*$. If $f$ is totally computable and
\begin{gather*}
	f\colon \Sigma^*\rightarrow\Gamma^*, A\subseteq \Sigma^*, B\subseteq \Gamma^*\\
	\forall w\in\Sigma^*\colon w\in A \iff f(w)\in B
\end{gather*}
then $f$ is a reduction from $\Sigma^*$ to $\Gamma^*$.\newline
In practise our formal languages $A$ and $B$ will be some instances of types of infinite games together with statements about such games, such as the values under perfect play or perfect strategies. The reduction will then draw an equivalence to the other infinite game, e.g. if $w=``v(v_u)=5$ in $G$'' is a word in $A$ then $f(w) = ``v(v_v)=16$ in $H$'' is a word in $B$.
\section{Reductions and Solutions in Theory}
\subsection{Reductions in Theory}
\subsubsection{PGs to MPGs}
\subsubsection{MPGs to DPGs}
\subsubsection{MPGs to EGs}
\subsubsection{DPGs to SSGs}
\subsection{Solutions in Theory}
\subsubsection{Value Iteration}
\subsubsection{Strategy Iteration}
\subsubsection{PGs}
\subsubsection{MPGs}
\subsubsection{DPGs}
\subsubsection{EGs}
\subsubsection{SSGs}
\section{Reductions and Solutions in Practise}
\subsection{Reductions in Practise}
\subsection{Solutions in Practise}
\section{Implementation}
\section{Evaluation}
\section{Conclusion and further approaches}
